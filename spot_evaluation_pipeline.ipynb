{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5e689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from inspect_ai import Task, eval as inspect_eval, score\n",
    "from inspect_ai.dataset import Dataset, Sample\n",
    "from inspect_ai.model import get_model\n",
    "from inspect_ai.solver import generate\n",
    "from inspect_ai.scorer import scorer, Score, accuracy, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65e8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bool(val):\n",
    "    if isinstance(val, bool):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        return val.strip().lower() in [\"true\", \"yes\", \"1\"]\n",
    "    return False\n",
    "\n",
    "@scorer(metrics=[accuracy(), stderr()])\n",
    "def spot_custom_scorer():\n",
    "    async def score(state, target):\n",
    "        output = state.output.completion\n",
    "        try:\n",
    "            target_dict = json.loads(target.text) if hasattr(target, 'text') else dict(target)\n",
    "        except Exception:\n",
    "            target_dict = {}\n",
    "        gt_errors_detected = parse_bool(target_dict.get(\"errors_detected\", None))\n",
    "        gt_specific_error_found = parse_bool(target_dict.get(\"specific_error_found\", None))\n",
    "        gt_matches_human = parse_bool(target_dict.get(\"matches_human_annotation\", None))\n",
    "\n",
    "        try:\n",
    "            json_match = re.search(r'\\{.*\\}', output, re.DOTALL)\n",
    "            if json_match:\n",
    "                model_out = json.loads(json_match.group())\n",
    "            else:\n",
    "                model_out = {}\n",
    "        except Exception:\n",
    "            model_out = {}\n",
    "        mdl_errors_detected = parse_bool(model_out.get(\"errors_detected\", None))\n",
    "        mdl_specific_error_found = parse_bool(model_out.get(\"specific_error_found\", None))\n",
    "        mdl_matches_human = parse_bool(model_out.get(\"matches_human_annotation\", None))\n",
    "        confidence = model_out.get(\"confidence\", None)\n",
    "        error_description = model_out.get(\"error_description\", \"\")\n",
    "\n",
    "        matches = [\n",
    "            gt_errors_detected == mdl_errors_detected,\n",
    "            gt_specific_error_found == mdl_specific_error_found,\n",
    "            gt_matches_human == mdl_matches_human\n",
    "        ]\n",
    "        num_matches = sum(matches)\n",
    "        if num_matches == 3:\n",
    "            value = 1.0\n",
    "        elif num_matches == 2:\n",
    "            value = 0.66\n",
    "        elif num_matches == 1:\n",
    "            value = 0.33\n",
    "        else:\n",
    "            value = 0.0\n",
    "\n",
    "        explanation = (\n",
    "            f\"errors_detected: {'✅' if matches[0] else '❌'} | \"\n",
    "            f\"specific_error_found: {'✅' if matches[1] else '❌'} | \"\n",
    "            f\"matches_human_annotation: {'✅' if matches[2] else '❌'}\\n\"\n",
    "            f\"Model confidence: {confidence}\\n\"\n",
    "            f\"Model error_description: {error_description[:200]}{'...' if len(error_description) > 200 else ''}\"\n",
    "        )\n",
    "        return Score(value=value, explanation=explanation)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97af33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/21/25 17:49:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running 1 tasks...                                                          <a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/run.py#267\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">267</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/21/25 17:49:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running 1 tasks...                                                          \u001b]8;id=925183;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=798465;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/run.py#267\u001b\\\u001b[2m267\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Task: spot_inference_task, Model: anthropic/claude-3-5-haiku-20241022,      <a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#311\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Steps: 0/10 0%, Samples: 0/10, , HTTP retries: 0                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Task: spot_inference_task, Model: anthropic/claude-3-5-haiku-20241022,      \u001b]8;id=552928;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=74454;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#311\u001b\\\u001b[2m311\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Steps: 0/10 0%, Samples: 0/10, , HTTP retries: 0                            \u001b[2m          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/21/25 17:49:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Task: spot_inference_task, Model: anthropic/claude-3-5-haiku-20241022,      <a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#406\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">406</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Steps: 10/10 100%, Samples: 10/10, anthropic: 0/10, HTTP retries: 0         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/21/25 17:49:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Task: spot_inference_task, Model: anthropic/claude-3-5-haiku-20241022,      \u001b]8;id=297724;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=107027;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#406\u001b\\\u001b[2m406\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Steps: 10/10 100%, Samples: 10/10, anthropic: 0/10, HTTP retries: 0         \u001b[2m          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> spot_inference_task (10 samples): anthropic/claude-3-5-haiku-20241022       <a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         succeeded                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         dataset: Simple Dataset                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         total time: 0:00:03                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         anthropic/claude-3-5-haiku-20241022:  9,473 tokens [I: 8,303, CW: 0, CR: 0, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         O: 1,170]                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m spot_inference_task (10 samples): anthropic/claude-3-5-haiku-20241022       \u001b]8;id=10130;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=13817;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         succeeded                                                                   \u001b[2m          \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         dataset: Simple Dataset                                                     \u001b[2m          \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         total time: 0:00:03                                                         \u001b[2m          \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         anthropic/claude-3-5-haiku-20241022:  9,473 tokens [I: 8,303, CW: 0, CR: 0, \u001b[2m          \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         O: 1,170]                                                                   \u001b[2m          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> 1/1 tasks complete                                                          <a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m 1/1 tasks complete                                                          \u001b]8;id=551979;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=327851;file:///Users/tommyly/ai4s_r2/spot_env/lib/python3.13/site-packages/inspect_ai/_eval/task/run.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory: /var/folders/qy/nwfw_b_s0qq095_lq9ykgdcr0000gn/T/inspect_ai_logs_evp4iwn0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'YOUR-CLAUDE-API-KEY HERE'\n",
    "\n",
    "# Load dataset\n",
    "with open(\"spot_dataset.json\") as f:\n",
    "    df = json.load(f)\n",
    "\n",
    "# Create dataset for inspect_ai\n",
    "samples = []\n",
    "for i, row in enumerate(df[:10]):  # Change [:2] to [:N] for more samples\n",
    "    paper_content = row[\"paper_content\"]\n",
    "    if isinstance(paper_content, list):\n",
    "        text_parts = []\n",
    "        for chunk in paper_content:\n",
    "            if isinstance(chunk, dict) and chunk.get('text'):\n",
    "                text_parts.append(chunk['text'])\n",
    "        paper_text = '\\n\\n'.join(text_parts)\n",
    "    else:\n",
    "        paper_text = str(paper_content)\n",
    "    prompt = f\"\"\"\n",
    "You are a scientific rigor auditor specializing in academic paper verification. \n",
    "\n",
    "PAPER CONTENT:\n",
    "{paper_text[:2000]}\n",
    "\n",
    "KNOWN ERROR INFORMATION:\n",
    "- Error Category: {row['error_category']}\n",
    "- Error Location: {row['error_location']}\n",
    "- Human Annotation: {row['error_annotation']}\n",
    "\n",
    "Your task is to analyze this paper and determine:\n",
    "1. Whether you can detect the specific error mentioned in the human annotation\n",
    "2. If you can identify any other scientific errors\n",
    "3. How well your analysis matches the human annotation\n",
    "\n",
    "Please respond in this exact JSON format:\n",
    "{{\n",
    "    \\\"errors_detected\\\": true/false,\n",
    "    \\\"specific_error_found\\\": true/false,\n",
    "    \\\"error_description\\\": \\\"detailed description of errors found\\\",\n",
    "    \\\"matches_human_annotation\\\": true/false,\n",
    "    \\\"confidence\\\": 0.0-1.0\n",
    "}}\n",
    "\n",
    "Respond only with the JSON object, no additional text.\n",
    "\"\"\"\n",
    "    # Target for scoring\n",
    "    target = {\n",
    "        \"errors_detected\": row.get(\"errors_detected\", None),\n",
    "        \"specific_error_found\": row.get(\"specific_error_found\", None),\n",
    "        \"matches_human_annotation\": row.get(\"matches_human_annotation\", None)\n",
    "    }\n",
    "    target_str = json.dumps(target)\n",
    "    samples.append(Sample(input=prompt, target=target_str, id=f\"paper_{i}\"))\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self._samples = samples\n",
    "    def __getitem__(self, index):\n",
    "        return self._samples[index]\n",
    "    def __len__(self):\n",
    "        return len(self._samples)\n",
    "    def filter(self, predicate, name=None):\n",
    "        filtered_samples = [s for s in self._samples if predicate(s)]\n",
    "        return SimpleDataset(filtered_samples)\n",
    "    def shuffle(self, seed=None):\n",
    "        import random\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        random.shuffle(self._samples)\n",
    "    def shuffle_choices(self, seed=None):\n",
    "        pass\n",
    "    def sort(self, reverse=False, key=None):\n",
    "        if key is None:\n",
    "            def default_key(sample):\n",
    "                return len(str(sample.input))\n",
    "            key = default_key\n",
    "        self._samples.sort(key=key, reverse=reverse)\n",
    "    @property\n",
    "    def location(self):\n",
    "        return \"simple_dataset\"\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"Simple Dataset\"\n",
    "    @property\n",
    "    def shuffled(self):\n",
    "        return False\n",
    "\n",
    "dataset = SimpleDataset(samples)\n",
    "model = get_model(\"anthropic/claude-3-5-haiku-20241022\")\n",
    "task = Task(\n",
    "    dataset=dataset,\n",
    "    solver=generate(),\n",
    "    name=\"spot_inference_task\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "import tempfile\n",
    "log_dir = tempfile.mkdtemp(prefix=\"inspect_ai_logs_\")\n",
    "results = inspect_eval(\n",
    "    tasks=task,\n",
    "    model=model,\n",
    "    limit=len(samples),\n",
    "    display=\"log\",\n",
    "    log_dir=log_dir,\n",
    "    log_format=\"json\",\n",
    "    log_level=\"info\"\n",
    ")\n",
    "print(f\"Log directory: {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55765bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples created: 10\n",
      "Log directory: /var/folders/qy/nwfw_b_s0qq095_lq9ykgdcr0000gn/T/inspect_ai_logs_evp4iwn0\n",
      "Log files: ['/var/folders/qy/nwfw_b_s0qq095_lq9ykgdcr0000gn/T/inspect_ai_logs_evp4iwn0/2025-07-21T17-49-21-04-00_spot-inference-task_idrtshiV8tTF6dBShrEBZk.json']\n",
      "Samples in log: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples created: {len(samples)}\")\n",
    "print(\"Log directory:\", log_dir)\n",
    "log_files = glob.glob(os.path.join(log_dir, \"*.json\"))\n",
    "print(\"Log files:\", log_files)\n",
    "with open(log_files[0]) as f:\n",
    "    data = json.load(f)\n",
    "print(\"Samples in log:\", len(data.get('samples', [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b67facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored log written to: /var/folders/qy/nwfw_b_s0qq095_lq9ykgdcr0000gn/T/inspect_ai_logs_evp4iwn0/2025-07-21T17-49-21-04-00_spot-inference-task_idrtshiV8tTF6dBShrEBZk_scored.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from inspect_ai.log import read_eval_log, write_eval_log\n",
    "from inspect_ai import score\n",
    "from spot_custom_scorer import spot_custom_scorer  # adjust if your scorer is elsewhere\n",
    "\n",
    "def find_latest_log():\n",
    "    log_pattern = \"/var/folders/qy/nwfw_b_s0qq095_lq9ykgdcr0000gn/T/inspect_ai_logs_*/\"\n",
    "    log_dirs = glob.glob(log_pattern)\n",
    "    if not log_dirs:\n",
    "        print(\"❌ No log directories found\")\n",
    "        return None\n",
    "    latest_dir = max(log_dirs, key=os.path.getctime)\n",
    "    # Only get raw logs (not already scored)\n",
    "    json_files = [f for f in glob.glob(os.path.join(latest_dir, \"*.json\")) if not f.endswith(\"_scored.json\")]\n",
    "    if not json_files:\n",
    "        print(\"❌ No raw JSON files found in log directory\")\n",
    "        return None\n",
    "    return max(json_files, key=os.path.getctime)\n",
    "\n",
    "log_file = find_latest_log()\n",
    "if log_file is None:\n",
    "    raise FileNotFoundError(\"No log file found.\")\n",
    "\n",
    "log = read_eval_log(log_file)\n",
    "scored_log = score(log, spot_custom_scorer())\n",
    "base, ext = os.path.splitext(log_file)\n",
    "scored_file = base + \"_scored\" + ext\n",
    "write_eval_log(scored_log, scored_file)\n",
    "print(f\"✅ Scored log written to: {scored_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25b7dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/var/folders/qy/nwfw_b_s0qq095_lq9ykgdcr0000gn/T/inspect_ai_logs_evp4iwn0/2025-07-21T17-49-21-04-00_spot-inference-task_idrtshiV8tTF6dBShrEBZk_scored.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6237027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to spot_results.json\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample in data.get('samples', []):\n",
    "    sample_id = sample.get('id')\n",
    "    timing = {\n",
    "        'total_time': sample.get('total_time', 0),\n",
    "        'working_time': sample.get('working_time', 0)\n",
    "    }\n",
    "    score_val = None\n",
    "    explanation = None\n",
    "    scores = sample.get('scores')\n",
    "    if isinstance(scores, list) and len(scores) > 0:\n",
    "        # Most common case: list of dicts\n",
    "        score_val = scores[0].get('value')\n",
    "        explanation = scores[0].get('explanation')\n",
    "    elif isinstance(scores, dict) and scores:\n",
    "        # Sometimes scores is a dict of metrics\n",
    "        first_score = next(iter(scores.values()))\n",
    "        if isinstance(first_score, dict):\n",
    "            score_val = first_score.get('value')\n",
    "            explanation = first_score.get('explanation')\n",
    "    results.append({\n",
    "        'id': sample_id,\n",
    "        'timing': timing,\n",
    "        'score': score_val,\n",
    "        'explanation': explanation\n",
    "    })\n",
    "\n",
    "with open(\"spot_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"✅ Results saved to spot_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44059991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                        timing  score  \\\n",
      "0  paper_0    {'total_time': 3.384, 'working_time': 3.2}   0.66   \n",
      "1  paper_1  {'total_time': 3.569, 'working_time': 3.404}   0.00   \n",
      "2  paper_2  {'total_time': 2.411, 'working_time': 2.254}   1.00   \n",
      "3  paper_3  {'total_time': 3.301, 'working_time': 3.171}   0.00   \n",
      "4  paper_4  {'total_time': 3.492, 'working_time': 3.382}   0.66   \n",
      "\n",
      "                                         explanation  \n",
      "0  errors_detected: ❌ | specific_error_found: ✅ |...  \n",
      "1  errors_detected: ❌ | specific_error_found: ❌ |...  \n",
      "2  errors_detected: ✅ | specific_error_found: ✅ |...  \n",
      "3  errors_detected: ❌ | specific_error_found: ❌ |...  \n",
      "4  errors_detected: ❌ | specific_error_found: ✅ |...  \n",
      "Mean score: 0.664\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"spot_results.json\")\n",
    "print(df.head())\n",
    "print(\"Mean score:\", df['score'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
